{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones et attrition des clients bancaires\n",
    "\n",
    "Réseau de neurones avec Python (Keras)\n",
    "\n",
    "## La problématique\n",
    "\n",
    "On s'intéresse ici à une problème classique du domaine bancaire (mais pas que !) qui est l'attrition ou *churn* en anglais et correspond à la perte de client. \n",
    "Récemment de nombreux clients ont quitté la banque Crédit Friqué. La question est de comprendre pourquoi ces départs ?\n",
    "\n",
    "## Les données\n",
    "\n",
    "Pour répondre à cette question, la banque a sélectionné 6 mois plus tôt un sous ensemble de ses clients pour lesquels elle a stocké un certain nombre d’information puis, dans les 6 mois qui ont suivis, elle a observé si les clients avaient quitté ou non la banque. Vous voilà donc, 6 mois plus tard, contacté par la banque qui vous propose un beau dataset (pour une fois!) et vous demande de déterminer les profils des clients les plus à même de partir.\n",
    "Vous disposez du fichier banque_abandon.csv qui est la base de données de la banque virtuelle Crédit Friqué.\n",
    "\n",
    "## Quelques questions préliminaires\n",
    "\n",
    "C'est juste pour vous échauffer donc ça doit être fait en moins d'une heure ça !\n",
    "1. À quoi correspondent les différentes variables du datasets ?\n",
    "2. Pour pas perdre les bonnes habitudes, faites quelques visualisations pour voir ce qu'il y a dans vos données.\n",
    "3. À quelle type de problème avez-vous à faire ici : classification ou régression ?\n",
    ">- Lister un certain nombre de modèles vous permettant de le résoudre\n",
    ">- Lister les métriques associées à ce type de problème\n",
    ">- Choisir un modèle, l'entraîner et l'évaluer avec la métrique de votre choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alors là, flemme de refaire et puis vous êtes censés être au point là-dessus depuis le temps...si y a des questions, évidemment, posez-les"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dans le vif du sujet\n",
    "\n",
    "Vous l'aurez compris, il s'agit ici de résoudre le problème à l'aide d'un réseau de neurones.   \n",
    "Vous aurez bien sûr besoin du package `keras` et il vous faudra aussi certainement installer `tensorflow`(et peut-être `theano` si besoin).  \n",
    "À vous de jouer !\n",
    "N'oubliez pas le preprocessing !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "df = pd.read_csv('data/banque_abandon.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création des tables X et y\n",
    "X = df.iloc[:, 3:13] #pour pas prendre les variable id, name et label\n",
    "y = df.iloc[:, 13] #juste le label\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography\n",
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.value_counts('Geography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding sur variables catégoriques\n",
    "# et feature scaling sur variables numériques\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "preprocess = make_column_transformer(\n",
    "        (OneHotEncoder(), ['Geography', 'Gender']),\n",
    "        (StandardScaler(), ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "                            'NumOfProducts', 'HasCrCard', 'IsActiveMember', \n",
    "                            'EstimatedSalary']))\n",
    "X = preprocess.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillons test et train\n",
    "#y = y.values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4783 - accuracy: 0.7958\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4273 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.4228 - accuracy: 0.8089\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4194 - accuracy: 0.8230\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4169 - accuracy: 0.8266\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4148 - accuracy: 0.8294\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4132 - accuracy: 0.8305\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4119 - accuracy: 0.8319\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4107 - accuracy: 0.8320\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4095 - accuracy: 0.8339\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4087 - accuracy: 0.8354\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4079 - accuracy: 0.8350\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4066 - accuracy: 0.8347\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4062 - accuracy: 0.8335\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4059 - accuracy: 0.8347\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.4051 - accuracy: 0.8341\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4044 - accuracy: 0.8344\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4047 - accuracy: 0.8351\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4039 - accuracy: 0.8359\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4035 - accuracy: 0.8342\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.4031 - accuracy: 0.8355\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4030 - accuracy: 0.8365\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4027 - accuracy: 0.8345\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4025 - accuracy: 0.8341\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4025 - accuracy: 0.8361\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4022 - accuracy: 0.8347\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4019 - accuracy: 0.8353\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.4016 - accuracy: 0.8359\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.4021 - accuracy: 0.8346\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4019 - accuracy: 0.8347\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4013 - accuracy: 0.8339\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.4017 - accuracy: 0.8350\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4014 - accuracy: 0.8360\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4014 - accuracy: 0.8350\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4010 - accuracy: 0.8350\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4013 - accuracy: 0.8365\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4015 - accuracy: 0.8351\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 4s 6ms/step - loss: 0.4011 - accuracy: 0.8341\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4010 - accuracy: 0.8364\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4011 - accuracy: 0.8351\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4007 - accuracy: 0.8351\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4011 - accuracy: 0.8342\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 0.4004 - accuracy: 0.8349\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.4007 - accuracy: 0.8360\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.4007 - accuracy: 0.8353\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4009 - accuracy: 0.8344\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4005 - accuracy: 0.8356\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4007 - accuracy: 0.8346\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4009 - accuracy: 0.8345\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4002 - accuracy: 0.8338\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4005 - accuracy: 0.8354\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.4007 - accuracy: 0.8345\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4004 - accuracy: 0.8349\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4007 - accuracy: 0.8350\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4004 - accuracy: 0.8350\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4002 - accuracy: 0.8342\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4000 - accuracy: 0.8346\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4001 - accuracy: 0.8363\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4004 - accuracy: 0.8347\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4005 - accuracy: 0.8360\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4000 - accuracy: 0.8354\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4003 - accuracy: 0.8338\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4000 - accuracy: 0.8350\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4003 - accuracy: 0.8349\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4004 - accuracy: 0.8342\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3995 - accuracy: 0.8342\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4001 - accuracy: 0.8350\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4004 - accuracy: 0.8364\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.3998 - accuracy: 0.8378\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4003 - accuracy: 0.8355\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3998 - accuracy: 0.8346\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3999 - accuracy: 0.8351\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3999 - accuracy: 0.8342\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4000 - accuracy: 0.8346\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3997 - accuracy: 0.8353\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 4s 6ms/step - loss: 0.4000 - accuracy: 0.8356\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4001 - accuracy: 0.8350\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3995 - accuracy: 0.8350\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.4000 - accuracy: 0.8363\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3999 - accuracy: 0.8350\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4000 - accuracy: 0.8354\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3998 - accuracy: 0.8359\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3997 - accuracy: 0.8344\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3999 - accuracy: 0.8350\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4002 - accuracy: 0.8347\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.4000 - accuracy: 0.8342\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3998 - accuracy: 0.8342\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.4001 - accuracy: 0.8360\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3995 - accuracy: 0.8351\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3999 - accuracy: 0.8347\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3995 - accuracy: 0.8357\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3999 - accuracy: 0.8335\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 6s 7ms/step - loss: 0.3995 - accuracy: 0.8346\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 5s 7ms/step - loss: 0.3999 - accuracy: 0.8347\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3997 - accuracy: 0.8360\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.3997 - accuracy: 0.8340\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 7s 8ms/step - loss: 0.3995 - accuracy: 0.8346\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.3996 - accuracy: 0.8350\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.3996 - accuracy: 0.8349\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 6s 8ms/step - loss: 0.3997 - accuracy: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb4fc029ed0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Architecture\n",
    "mlp_clf = Sequential()\n",
    "mlp_clf.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
    "mlp_clf.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "mlp_clf.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Paramètres d'apprentissage\n",
    "mlp_clf.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Entraînement\n",
    "mlp_clf.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39585408568382263, 0.840499997138977]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "mlp_clf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur le test set\n",
    "y_pred = mlp_clf.predict(X_test)\n",
    "y_pred = 1*(y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1549,   46],\n",
       "       [ 273,  132]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.09119666]], dtype=float32), array([[False]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prédiction pour un nouveau client\n",
    "\"\"\"On veut prédire si le client suivant va quitter la banque:\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40\n",
    "Tenure: 3\n",
    "Balance: 60000\n",
    "Number of Products: 2\n",
    "Has Credit Card: Yes\n",
    "Is Active Member: Yes\n",
    "Estimated Salary: 50000\"\"\"\n",
    "Xnew = pd.DataFrame(data={\n",
    "        'CreditScore': [600], \n",
    "        'Geography': ['France'], \n",
    "        'Gender': ['Male'],\n",
    "        'Age': [40],\n",
    "        'Tenure': [3],\n",
    "        'Balance': [60000],\n",
    "        'NumOfProducts': [2],\n",
    "        'HasCrCard': [1],\n",
    "        'IsActiveMember': [1],\n",
    "        'EstimatedSalary': [50000]})\n",
    "Xnew = preprocess.transform(Xnew)\n",
    "new_prediction = mlp_clf.predict(Xnew)\n",
    "new_prediction, (new_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation du réseau et affinage des hyper-paramètres\n",
    "\n",
    "Jusqu'à maintenant, on a évalué les réseaux qu'on a vu en regardant uniquement l'accuracy mais cette valeur n'est pas déterministe puisqu'elle dépend de certains paramètres aléatoires comme le train_test_split, l'intialisation des paramètres etc...\n",
    "\n",
    "Une solution par rapport à ce problème est de répéter l'entraînement plusieurs fois et de regarder les résultats en moyenne. On l'a déjà utilisé et ça s'appelle la validation croisée.\n",
    "\n",
    "Mettez en place la validation croisée en utilisant `cross_val_score` puis affiner les paramètres avec `GridSearchCV`.\n",
    "\n",
    "**/!\\\\** Vous aurez besoin de ce qu'on appelle un wrapper pour pouvoir relier `keras` à `sklearn` et utiliser un modèle de l'un dans l'autre. Ça tombe bien, ça existe : regarder la librairie `keras.wrappers.scikit_learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction de création du modèle\n",
    "def build_classifier(optimizer='adam'):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée avec cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, \n",
    "                             cv = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85874999, 0.85250002, 0.88      , 0.85124999, 0.86750001,\n",
       "       0.82999998, 0.86500001, 0.82249999, 0.83999997, 0.84375   ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8511249959468842, 0.016728069665139542)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean(), accuracies.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Affinage d'hyper-paramètres par validation croisée : GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [5, 25],\n",
    "              'epochs': [100], #, 300\n",
    "              'optimizer': ['adam']} #, 'rmsprop'\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 8)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_, grid_search.best_score_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde et chargement des réseaux\n",
    "\n",
    "Regarder les méthodes `save` et `load_model` de la librairie `keras.models` pour la sauvegarde et le chargement des modèle. Quel format de fichier utiliser ?\n",
    "\n",
    "Si vous souhaitez ne sauvegarder que l'architecture du modèle (sans les poids ni la configuration d'entraînement), vous pouvez utiliser `to_json`.\n",
    "\n",
    "Enfin, pour ne sauvegarder que les poids, vous avez la méthode `save_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.save()\n",
    "\n",
    "Cette fonction sauvegarde:\n",
    "- L'architecture du modèle, permettant de le recréer si nécessaire\n",
    "- Les poids du modèles\n",
    "- Les paramètres d'apprentissage (loss, optimizer, metrics dans l'étape `compile`).\n",
    "- L'état de l'optimisation ce qui permet de reprendre l'apprentissage où on l'avait laissé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf.save('models/mlp_clf_bankchurn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.load_model()\n",
    "\n",
    "Cette fonction charge un modèle enregistré et l'ensemble de ses infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('models/mlp_clf_bankchurn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 3.8806319e-01, -1.2984583e-01,  1.4795303e-01,  3.9133728e-01,\n",
       "          5.0764030e-01,  5.8275330e-01],\n",
       "        [ 1.9088547e-01,  7.5540558e-02, -3.6283594e-02,  2.4065277e-01,\n",
       "          2.4200870e-01, -2.7432445e-01],\n",
       "        [ 4.1927108e-01,  1.9702022e-01,  2.2537884e-01,  3.7907854e-01,\n",
       "          1.9322513e-01,  4.8168102e-01],\n",
       "        [ 4.0389273e-01, -4.3642536e-02, -6.1504757e-01,  4.2023441e-01,\n",
       "          3.8203853e-01,  1.6709088e-01],\n",
       "        [ 3.3347964e-01,  1.0324735e-03,  6.8761152e-01,  4.1838554e-01,\n",
       "          4.5580164e-01,  5.1387954e-01],\n",
       "        [ 1.2557963e-02,  3.4691364e-02,  2.6383467e-02,  2.7291201e-02,\n",
       "          4.6784915e-02,  6.6219717e-02],\n",
       "        [-7.7856427e-01,  5.8970433e-01, -4.0223137e-01, -8.5811847e-01,\n",
       "         -8.5488600e-01,  1.4521357e-01],\n",
       "        [-1.6854433e-02, -3.9606830e-03,  1.2825899e-01, -3.9928023e-02,\n",
       "         -3.5306577e-02,  1.5700513e-01],\n",
       "        [ 5.4187063e-02,  2.1316906e-02, -4.5991766e-01,  4.0319629e-02,\n",
       "          4.4184066e-02, -2.6602501e-01],\n",
       "        [ 1.9321896e-02, -8.1134431e-02,  1.1219634e-01,  1.6780270e-02,\n",
       "          4.7735598e-02,  6.1168682e-02],\n",
       "        [ 8.7240808e-02,  2.0387337e-01, -4.0402472e-02,  7.8473471e-02,\n",
       "         -6.1713800e-02, -1.4007735e-01],\n",
       "        [-2.9745880e-01,  1.1631612e+00, -1.2928909e-01, -3.1960654e-01,\n",
       "         -2.7920389e-01,  6.1068839e-01],\n",
       "        [ 7.1799986e-02,  1.8159127e-01,  2.2513956e-01,  8.5290886e-02,\n",
       "          8.1721261e-02, -4.5511103e-01]], dtype=float32),\n",
       " array([ 0.46878102, -0.05946148,  0.07512679,  0.5395293 ,  0.5123707 ,\n",
       "         0.42275962], dtype=float32),\n",
       " array([[-0.03629891, -0.00258519,  0.39780802, -0.01355626,  0.35958162,\n",
       "          0.3426306 ],\n",
       "        [ 0.00344431, -0.00512417,  0.6706302 , -0.04795563,  0.63924897,\n",
       "          0.6645442 ],\n",
       "        [-0.00701521, -0.02641344,  0.27025068,  0.0128972 ,  0.29790333,\n",
       "          0.21913514],\n",
       "        [-0.00175352, -0.04425125,  0.497123  , -0.033461  ,  0.46958697,\n",
       "          0.47044545],\n",
       "        [-0.02240413,  0.01863723,  0.4799448 , -0.00149747,  0.46600416,\n",
       "          0.523311  ],\n",
       "        [-0.05225598, -0.00328053,  0.49222586, -0.04534667,  0.51723665,\n",
       "          0.51661474]], dtype=float32),\n",
       " array([-0.01359748, -0.01610462, -0.35012817, -0.0099482 , -0.34326497,\n",
       "        -0.34806225], dtype=float32),\n",
       " array([[ 0.03392169],\n",
       "        [ 0.00472387],\n",
       "        [-0.47766313],\n",
       "        [ 0.02262168],\n",
       "        [-0.48660952],\n",
       "        [-0.4962974 ]], dtype=float32),\n",
       " array([1.9180626], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7fb4b45c8350>,\n",
       " <function tensorflow.python.keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer, new_model.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.to_json()\n",
    "\n",
    "Si on a juste besoin de sauvegarder la structure d'un réseau, sans ses poids ni ses paramètres d'entraînement, on peut utiliser un de ces deux fonctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 13], \"dtype\": \"float32\", \"units\": 6, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 6, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"build_input_shape\": [null, 13]}, \"keras_version\": \"2.3.0-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sauvegarder au format json\n",
    "json_string = mlp_clf.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruire un modèle depuis JSON\n",
    "from tensorflow.keras.models import model_from_json\n",
    "new_model2 = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.01700081, -0.00347238,  0.02844789,  0.0320172 , -0.0301837 ,\n",
       "         -0.03008308],\n",
       "        [-0.03238676, -0.00604498, -0.02940136,  0.00465361,  0.00886982,\n",
       "          0.0193612 ],\n",
       "        [ 0.0264228 ,  0.04061887, -0.02440124,  0.03010553,  0.0001804 ,\n",
       "          0.04316676],\n",
       "        [-0.01615125, -0.04594085, -0.0428838 , -0.0362407 , -0.02900125,\n",
       "         -0.02112159],\n",
       "        [ 0.01483382, -0.03038022, -0.02934878, -0.00454221, -0.00641793,\n",
       "         -0.03834749],\n",
       "        [-0.02947449,  0.02840732,  0.0369069 ,  0.00082551, -0.04039915,\n",
       "         -0.00138519],\n",
       "        [ 0.01509402,  0.03247241,  0.04245781,  0.01226106, -0.02212368,\n",
       "          0.03888113],\n",
       "        [ 0.02721557,  0.04825569, -0.00094674,  0.02095871, -0.04847995,\n",
       "         -0.02789102],\n",
       "        [-0.01249887,  0.01965458,  0.04944919,  0.01430814, -0.02584171,\n",
       "         -0.03950638],\n",
       "        [ 0.01748535,  0.03361266,  0.03466997,  0.00238124,  0.02550166,\n",
       "         -0.00499903],\n",
       "        [-0.00866221,  0.03189551,  0.00242579,  0.02015075, -0.0135165 ,\n",
       "          0.00693909],\n",
       "        [ 0.02304734, -0.00985894,  0.04558391, -0.01181887,  0.04917068,\n",
       "         -0.04197266],\n",
       "        [-0.04316114,  0.00998949,  0.0172307 , -0.04133784, -0.00715254,\n",
       "         -0.0384177 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.01728724,  0.00179453,  0.0087178 ,  0.01877937,  0.02689339,\n",
       "         -0.00361291],\n",
       "        [ 0.0427912 , -0.04550414,  0.00795222,  0.00696646,  0.01268155,\n",
       "          0.04089608],\n",
       "        [-0.0130542 , -0.01817523, -0.01826017, -0.04527762,  0.04447862,\n",
       "          0.03928513],\n",
       "        [-0.00891655,  0.03810736,  0.0377408 ,  0.04789149,  0.01371722,\n",
       "         -0.03299121],\n",
       "        [-0.0052448 , -0.0475167 , -0.0479123 , -0.011569  , -0.04086567,\n",
       "          0.01496288],\n",
       "        [ 0.02105966,  0.01574436, -0.00726795,  0.02600542,  0.02907674,\n",
       "         -0.01167632]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.03599538],\n",
       "        [-0.03766996],\n",
       "        [ 0.03528846],\n",
       "        [ 0.02286842],\n",
       "        [-0.04468226],\n",
       "        [-0.00191985]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model2.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.save_weights()\n",
    "\n",
    "Si jamais on veut uniquement les poids d'un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf.save_weights('models/mes_poids.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model3 = Sequential([\n",
    "    Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13),\n",
    "    Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'),\n",
    "    Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model3.load_weights('models/mes_poids.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 3.8806319e-01, -1.2984583e-01,  1.4795303e-01,  3.9133728e-01,\n",
       "          5.0764030e-01,  5.8275330e-01],\n",
       "        [ 1.9088547e-01,  7.5540558e-02, -3.6283594e-02,  2.4065277e-01,\n",
       "          2.4200870e-01, -2.7432445e-01],\n",
       "        [ 4.1927108e-01,  1.9702022e-01,  2.2537884e-01,  3.7907854e-01,\n",
       "          1.9322513e-01,  4.8168102e-01],\n",
       "        [ 4.0389273e-01, -4.3642536e-02, -6.1504757e-01,  4.2023441e-01,\n",
       "          3.8203853e-01,  1.6709088e-01],\n",
       "        [ 3.3347964e-01,  1.0324735e-03,  6.8761152e-01,  4.1838554e-01,\n",
       "          4.5580164e-01,  5.1387954e-01],\n",
       "        [ 1.2557963e-02,  3.4691364e-02,  2.6383467e-02,  2.7291201e-02,\n",
       "          4.6784915e-02,  6.6219717e-02],\n",
       "        [-7.7856427e-01,  5.8970433e-01, -4.0223137e-01, -8.5811847e-01,\n",
       "         -8.5488600e-01,  1.4521357e-01],\n",
       "        [-1.6854433e-02, -3.9606830e-03,  1.2825899e-01, -3.9928023e-02,\n",
       "         -3.5306577e-02,  1.5700513e-01],\n",
       "        [ 5.4187063e-02,  2.1316906e-02, -4.5991766e-01,  4.0319629e-02,\n",
       "          4.4184066e-02, -2.6602501e-01],\n",
       "        [ 1.9321896e-02, -8.1134431e-02,  1.1219634e-01,  1.6780270e-02,\n",
       "          4.7735598e-02,  6.1168682e-02],\n",
       "        [ 8.7240808e-02,  2.0387337e-01, -4.0402472e-02,  7.8473471e-02,\n",
       "         -6.1713800e-02, -1.4007735e-01],\n",
       "        [-2.9745880e-01,  1.1631612e+00, -1.2928909e-01, -3.1960654e-01,\n",
       "         -2.7920389e-01,  6.1068839e-01],\n",
       "        [ 7.1799986e-02,  1.8159127e-01,  2.2513956e-01,  8.5290886e-02,\n",
       "          8.1721261e-02, -4.5511103e-01]], dtype=float32),\n",
       " array([ 0.46878102, -0.05946148,  0.07512679,  0.5395293 ,  0.5123707 ,\n",
       "         0.42275962], dtype=float32),\n",
       " array([[-0.03629891, -0.00258519,  0.39780802, -0.01355626,  0.35958162,\n",
       "          0.3426306 ],\n",
       "        [ 0.00344431, -0.00512417,  0.6706302 , -0.04795563,  0.63924897,\n",
       "          0.6645442 ],\n",
       "        [-0.00701521, -0.02641344,  0.27025068,  0.0128972 ,  0.29790333,\n",
       "          0.21913514],\n",
       "        [-0.00175352, -0.04425125,  0.497123  , -0.033461  ,  0.46958697,\n",
       "          0.47044545],\n",
       "        [-0.02240413,  0.01863723,  0.4799448 , -0.00149747,  0.46600416,\n",
       "          0.523311  ],\n",
       "        [-0.05225598, -0.00328053,  0.49222586, -0.04534667,  0.51723665,\n",
       "          0.51661474]], dtype=float32),\n",
       " array([-0.01359748, -0.01610462, -0.35012817, -0.0099482 , -0.34326497,\n",
       "        -0.34806225], dtype=float32),\n",
       " array([[ 0.03392169],\n",
       "        [ 0.00472387],\n",
       "        [-0.47766313],\n",
       "        [ 0.02262168],\n",
       "        [-0.48660952],\n",
       "        [-0.4962974 ]], dtype=float32),\n",
       " array([1.9180626], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model3.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complément sur l'overfitting\n",
    "\n",
    "Toujours sur les données de la banque, entrainer un réseau ayant une structure complexe avec beaucoup de neurones et de couches afin de générer une situation d'overfitting.  \n",
    "Comparer l'accuracy sur les échantillons train et test pour confirmer le cas de sur-apprentissage.\n",
    "\n",
    "Reprendre le même réseau en utilisant des layers `Dropout` pour réduire ce problème.  \n",
    "Comparer à nouveau l'accuracy pour voir l'effet des `Dropout` sur l'overfitting.\n",
    "\n",
    "Une autre méthode pour limiter le sur-apprentissage est la régularisation. Est-il possible d'en faire avec un réseau de neurones ? Si oui, allez-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN - Situation d'overfitting\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
    "classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = classifier.evaluate(X_train, y_train) #0.9746\n",
    "score_test = classifier.evaluate(X_test, y_test) #0.8135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN - avec Dropout\n",
    "from keras.layers import Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = classifier.evaluate(X_train, y_train) #0.9045\n",
    "score_test = classifier.evaluate(X_test, y_test) #0.8465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN - avec régularisation l2\n",
    "from keras import regularizers\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
    "classifier.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "#ou kernel_regularizer=\"l2\"\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = classifier.evaluate(X_train, y_train) #0.8696\n",
    "score_test = classifier.evaluate(X_test, y_test) #0.8600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
