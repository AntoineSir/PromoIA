{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comprendre MapReduce**\n",
    "\n",
    "## **Map**\n",
    "\n",
    "```map``` prend en argument une fonction et une collection et retourne une collection. La fonction étant appliquée sur chaque élément de la collection.\n",
    "\n",
    "**Exo1:** Utiliser la fonction ```map``` pour multiplier par 2 les éléments d'une liste. Faire une version en définissant une fonction et une seconde version en utilisant une fonction anonyme ```lambda```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 4]\n",
      "[6, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "a = [3, 1, 2]\n",
    "\n",
    "#avec une fonction définie via def\n",
    "def fois_2(x):\n",
    "    return 2 * x\n",
    "\n",
    "b = map(fois_2, a)\n",
    "print(list(b))\n",
    "\n",
    "#avec une fonction anonyme\n",
    "c = map(lambda x: 2*x, a)\n",
    "print(list(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo2:** Créer une liste de 1000 entiers aléatoires. À l'aide de la fonction `map` retourner une collection qui contient `True` si le nombre était pair et `False` sinon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l = np.random.randint(10**6, size=1000)\n",
    "res = list(map(lambda a: a%2==0, l))\n",
    "#res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pour faire simple, la seule différence entre le ```map``` de python et celui de spark c'est que le ```map``` de ce dernier découpe le calul sur plusieurs machines pour paralléliser le traitement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reduce**\n",
    "\n",
    "La fonction ```reduce``` prend en entrée une collection et retourne une réduction de celle ci en lui appliquant une fonction d'agrégation itérative, c'est-à-dire, une fonction qui lit les valeurs de la liste de gauche à droite et ne renvoie qu'une seule valeur agrégée.  \n",
    "La fonction d'agrégation doit donc prendre 2 arguments et ne renvoyer qu'une seule valeur.\n",
    "\n",
    "Par exemple, ```reduce``` permet de calculer la somme des éléments d'une liste, ce qu'on va faire (enfin vous allez faire) de suite.\n",
    "\n",
    "**Exo3:** calculer la somme de la liste ```a``` :\n",
    ">1. en utilisant une boucle ```for```\n",
    ">2. en utilisant la fonction ```reduce``` du module ```functools```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som = 0\n",
    "for val in a :\n",
    "    som += val\n",
    "som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "som2 = reduce(lambda x,y : x+y, a, 0)\n",
    "som2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo4:** générer une liste de 20 entiers entre 0 et 1000 et calculer le maximum de cette liste à l'aide de la fonction ```reduce```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[754 591 613 230  56 304 565  55  49 914 866  71 310 347 420 114 812 216\n",
      " 316 832]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "914"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.randint(1000, size=20)\n",
    "print(b)\n",
    "maxi = reduce(lambda x,y : x if x>y else y, b)\n",
    "maxi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo5:** importer la fonction ```accumulate``` du module ```itertools```, comprendre comment elle marche, la tester et la comparer avec ```reduce``` sur les 2 exemples précédents (somme et maximum d'une liste). Quelles sont les différences ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour la somme : 15\n",
      "[1, 3, 6, 10, 15]\n",
      "\n",
      "Pour le maximum : 914\n",
      "[754, 754, 754, 754, 754, 754, 754, 754, 754, 914, 914, 914, 914, 914, 914, 914, 914, 914, 914, 914]\n"
     ]
    }
   ],
   "source": [
    "from itertools import accumulate\n",
    "print(\"Pour la somme :\", reduce(lambda x,y : x+y, a, 0))\n",
    "print(list(accumulate(a, lambda x,y : x+y)))\n",
    "print(\"\\nPour le maximum :\", reduce(lambda x,y : x if x>y else y, b))\n",
    "print(list(accumulate(b, lambda x,y : x if x>y else y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comme pour la fonction ```map``` la seule différence entre le ```reduce``` de python et celui de spark c'est que celui de spark découpe en plusieurs morceaux et parallélise le traitement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Petit bonus : Filter**\n",
    "\n",
    "\n",
    "**Exo6**: créer une liste avec les valeurs suivantes : [-1, 3, 2, -1, 6, 8] puis utiliser la fonction ```filter``` pour récupérer uniquement les valeurs positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 6, 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [-1, 3, 2, -1, 6, 8]\n",
    "list(filter(lambda x: x>0, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Map et Reduce**\n",
    "\n",
    "On considère le mega big dataset suivant : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"ceci n'est pas du big data\", 'Bonjour voilà du texte', \"il est en retard tous les jours\", \"une bonne auberge\", \"elle est en Grèce\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo7:** utiliser la fonction ```map``` pour séparer chaque phrase en en mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ceci', \"n'est\", 'pas', 'du', 'big', 'data'],\n",
       " ['Bonjour', 'voilà', 'du', 'texte'],\n",
       " ['il', 'est', 'en', 'retard', 'tous', 'les', 'jours'],\n",
       " ['une', 'bonne', 'auberge'],\n",
       " ['elle', 'est', 'en', 'Grèce']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda s: s.split(), a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo8:** à l'aide de ```map``` et/ou ```reduce``` renvoyer le nombre total de mots dans ```a```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = map(lambda phrase: len(phrase.split()), a)\n",
    "reduce(lambda x,y : x+y, mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **WordCount : le \"hello world\" du MapReduce**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo9:** on va illustrer le fonctionnement de MapReduce pour compter le nombre d'occurence de chaque mot dans la variable ```text``` définie ci-dessous. Il faut donc éxecuter les 4 étapes suivantes (le preprocessing étant un petit supplément) :\n",
    ">1. SPLIT: découpage du texte en 4 sous-parties\n",
    ">2. petite étape de peprocessing avec :\n",
    ">>- suppression de la ponctuation,\n",
    ">>- passage en minuscules\n",
    ">>- suppression des mots de 1, 2 ou 3 lettres\n",
    ">3. MAP: avec la fonction ```map``` renvoyer une liste de (clé, valeur) : ici clé=mot et valeur=occurence=1\n",
    ">4. SHUFFLE (& SORT): regroupement des résultats : on doit avoir pour chaque clé le couple (clé, [val, val, val,...]) : ici (mot, [1,1,1,...])\n",
    ">5. REDUCE: sommer les occurences uniques de chaque mot pour obtenir le nombre d'occurrences totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Si vous voulez mon avis concernant la morosité conjoncturelle, \\\n",
    "je n'exclus pas de réorganiser la simultanéité des hypothèses réalisables, \\\n",
    "avec toute la prudence requise. Eu égard à la fragilité actuelle, il ne faut \\\n",
    "pas s'interdire de se remémorer précisément les organisations matricielles \\\n",
    "opportunes, avec beaucoup de recul. Afin de circonvenir à cette inflexion de \\\n",
    "l'époque actuelle, je recommande d'essayer la somme des stratégies envisageables, \\\n",
    "même si ce n'est pas facile. Vu la dualité de la situation conjoncturelle, il ne \\\n",
    "faut pas négliger de gérer certaines synergies optimales, parce que nous le valons \\\n",
    "bien. Nonobstant la dualité de la situation observée, je n'exclus pas d'inventorier \\\n",
    "la somme des modalités réalisables, parce qu'il est temps d'agir. Si vous voulez mon \\\n",
    "avis concernant la baisse de confiance présente, je n'exclus pas d'inventorier la \\\n",
    "globalité des améliorations pertinentes, très attentivement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Si vous voulez mon avis concernant la morosité conjoncturelle, je n'exclus pas de réorganiser la simultanéité des hypothèses réalisables, avec toute la prudence requise. Eu égard à la fragilité actuelle, il ne faut pas\",\n",
       " \"s'interdire de se remémorer précisément les organisations matricielles opportunes, avec beaucoup de recul. Afin de circonvenir à cette inflexion de l'époque actuelle, je recommande d'essayer la somme des stratégies envisageables, même si ce n'est\",\n",
       " \"pas facile. Vu la dualité de la situation conjoncturelle, il ne faut pas négliger de gérer certaines synergies optimales, parce que nous le valons bien. Nonobstant la dualité de la situation observée, je n'exclus\",\n",
       " \"pas d'inventorier la somme des modalités réalisables, parce qu'il est temps d'agir. Si vous voulez mon avis concernant la baisse de confiance présente, je n'exclus pas d'inventorier la globalité des améliorations pertinentes, très attentivement.\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SPLIT\n",
    "mots = text.split()\n",
    "cuts = np.linspace(0, len(mots), 5, dtype=int)\n",
    "grp_mots = [mots[cuts[k]:cuts[k+1]] for k in range(4)]\n",
    "text_div = [\" \".join(grp_mots[k]) for k in range(4)]\n",
    "text_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing du text, on définit la fonction et l'applique directement à nos 4 sous-ensemble\n",
    "import string\n",
    "def preprocess(s):\n",
    "    temp = s.lower()\n",
    "    temp = temp.replace(\"'\",\" \")\n",
    "    temp = temp.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "\n",
    "    mots = temp.split()\n",
    "    gros_mots = list(filter(lambda x: len(x)>3, mots))\n",
    "    return \" \".join(gros_mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('vous', 1),\n",
       "  ('voulez', 1),\n",
       "  ('avis', 1),\n",
       "  ('concernant', 1),\n",
       "  ('morosité', 1),\n",
       "  ('conjoncturelle', 1),\n",
       "  ('exclus', 1),\n",
       "  ('réorganiser', 1),\n",
       "  ('simultanéité', 1),\n",
       "  ('hypothèses', 1),\n",
       "  ('réalisables', 1),\n",
       "  ('avec', 1),\n",
       "  ('toute', 1),\n",
       "  ('prudence', 1),\n",
       "  ('requise', 1),\n",
       "  ('égard', 1),\n",
       "  ('fragilité', 1),\n",
       "  ('actuelle', 1),\n",
       "  ('faut', 1)],\n",
       " [('interdire', 1),\n",
       "  ('remémorer', 1),\n",
       "  ('précisément', 1),\n",
       "  ('organisations', 1),\n",
       "  ('matricielles', 1),\n",
       "  ('opportunes', 1),\n",
       "  ('avec', 1),\n",
       "  ('beaucoup', 1),\n",
       "  ('recul', 1),\n",
       "  ('afin', 1),\n",
       "  ('circonvenir', 1),\n",
       "  ('cette', 1),\n",
       "  ('inflexion', 1),\n",
       "  ('époque', 1),\n",
       "  ('actuelle', 1),\n",
       "  ('recommande', 1),\n",
       "  ('essayer', 1),\n",
       "  ('somme', 1),\n",
       "  ('stratégies', 1),\n",
       "  ('envisageables', 1),\n",
       "  ('même', 1)],\n",
       " [('facile', 1),\n",
       "  ('dualité', 1),\n",
       "  ('situation', 1),\n",
       "  ('conjoncturelle', 1),\n",
       "  ('faut', 1),\n",
       "  ('négliger', 1),\n",
       "  ('gérer', 1),\n",
       "  ('certaines', 1),\n",
       "  ('synergies', 1),\n",
       "  ('optimales', 1),\n",
       "  ('parce', 1),\n",
       "  ('nous', 1),\n",
       "  ('valons', 1),\n",
       "  ('bien', 1),\n",
       "  ('nonobstant', 1),\n",
       "  ('dualité', 1),\n",
       "  ('situation', 1),\n",
       "  ('observée', 1),\n",
       "  ('exclus', 1)],\n",
       " [('inventorier', 1),\n",
       "  ('somme', 1),\n",
       "  ('modalités', 1),\n",
       "  ('réalisables', 1),\n",
       "  ('parce', 1),\n",
       "  ('temps', 1),\n",
       "  ('agir', 1),\n",
       "  ('vous', 1),\n",
       "  ('voulez', 1),\n",
       "  ('avis', 1),\n",
       "  ('concernant', 1),\n",
       "  ('baisse', 1),\n",
       "  ('confiance', 1),\n",
       "  ('présente', 1),\n",
       "  ('exclus', 1),\n",
       "  ('inventorier', 1),\n",
       "  ('globalité', 1),\n",
       "  ('améliorations', 1),\n",
       "  ('pertinentes', 1),\n",
       "  ('très', 1),\n",
       "  ('attentivement', 1)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAP\n",
    "def mapper(txt):\n",
    "    temp = preprocess(txt)\n",
    "    return [(mot,1) for mot in temp.split()]\n",
    "\n",
    "mapped = list(map(mapper, text_div)) #le \"map\" utilisé ici correspond en fait à la parallélisation du traitements:\n",
    "                                     #il faut le voir comme le fait d'effectuer en parallèle les opérations sur chaque sous-texte\n",
    "mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actuelle', [1, 1]),\n",
       " ('afin', [1]),\n",
       " ('agir', [1]),\n",
       " ('améliorations', [1]),\n",
       " ('attentivement', [1]),\n",
       " ('avec', [1, 1]),\n",
       " ('avis', [1, 1]),\n",
       " ('baisse', [1]),\n",
       " ('beaucoup', [1]),\n",
       " ('bien', [1]),\n",
       " ('certaines', [1]),\n",
       " ('cette', [1]),\n",
       " ('circonvenir', [1]),\n",
       " ('concernant', [1, 1]),\n",
       " ('confiance', [1]),\n",
       " ('conjoncturelle', [1, 1]),\n",
       " ('dualité', [1, 1]),\n",
       " ('envisageables', [1]),\n",
       " ('essayer', [1]),\n",
       " ('exclus', [1, 1, 1]),\n",
       " ('facile', [1]),\n",
       " ('faut', [1, 1]),\n",
       " ('fragilité', [1]),\n",
       " ('globalité', [1]),\n",
       " ('gérer', [1]),\n",
       " ('hypothèses', [1]),\n",
       " ('inflexion', [1]),\n",
       " ('interdire', [1]),\n",
       " ('inventorier', [1, 1]),\n",
       " ('matricielles', [1]),\n",
       " ('modalités', [1]),\n",
       " ('morosité', [1]),\n",
       " ('même', [1]),\n",
       " ('nonobstant', [1]),\n",
       " ('nous', [1]),\n",
       " ('négliger', [1]),\n",
       " ('observée', [1]),\n",
       " ('opportunes', [1]),\n",
       " ('optimales', [1]),\n",
       " ('organisations', [1]),\n",
       " ('parce', [1, 1]),\n",
       " ('pertinentes', [1]),\n",
       " ('prudence', [1]),\n",
       " ('précisément', [1]),\n",
       " ('présente', [1]),\n",
       " ('recommande', [1]),\n",
       " ('recul', [1]),\n",
       " ('remémorer', [1]),\n",
       " ('requise', [1]),\n",
       " ('réalisables', [1, 1]),\n",
       " ('réorganiser', [1]),\n",
       " ('simultanéité', [1]),\n",
       " ('situation', [1, 1]),\n",
       " ('somme', [1, 1]),\n",
       " ('stratégies', [1]),\n",
       " ('synergies', [1]),\n",
       " ('temps', [1]),\n",
       " ('toute', [1]),\n",
       " ('très', [1]),\n",
       " ('valons', [1]),\n",
       " ('voulez', [1, 1]),\n",
       " ('vous', [1, 1]),\n",
       " ('égard', [1]),\n",
       " ('époque', [1])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHUFFLE AND SORT: le but est de transformer la liste de listes de (mot,1) en une liste de (mot, [1,1,1,...,1]). Méthode \"naïve\".\n",
    "liste = [couple for div in mapped for couple in div] #on regroupe tous les couples (clé, valeur) dans une seule liste\n",
    "liste.sort() #on les trie\n",
    "\n",
    "cur_wd = None\n",
    "wd_occur = list()\n",
    "shuffled_sorted = list()\n",
    "\n",
    "for wd, cnt in liste:\n",
    "    if wd == cur_wd:\n",
    "        wd_occur.append(cnt)\n",
    "    else:\n",
    "        if cur_wd:\n",
    "            shuffled_sorted.append((cur_wd,wd_occur))\n",
    "        cur_wd, wd_occur = wd, [cnt]\n",
    "\n",
    "if cur_wd:\n",
    "    shuffled_sorted.append((cur_wd,wd_occur))\n",
    "    \n",
    "shuffled_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vous', [1, 1]),\n",
       " ('voulez', [1, 1]),\n",
       " ('avis', [1, 1]),\n",
       " ('concernant', [1, 1]),\n",
       " ('morosité', [1]),\n",
       " ('conjoncturelle', [1, 1]),\n",
       " ('exclus', [1, 1, 1]),\n",
       " ('réorganiser', [1]),\n",
       " ('simultanéité', [1]),\n",
       " ('hypothèses', [1]),\n",
       " ('réalisables', [1, 1]),\n",
       " ('avec', [1, 1]),\n",
       " ('toute', [1]),\n",
       " ('prudence', [1]),\n",
       " ('requise', [1]),\n",
       " ('égard', [1]),\n",
       " ('fragilité', [1]),\n",
       " ('actuelle', [1, 1]),\n",
       " ('faut', [1, 1]),\n",
       " ('interdire', [1]),\n",
       " ('remémorer', [1]),\n",
       " ('précisément', [1]),\n",
       " ('organisations', [1]),\n",
       " ('matricielles', [1]),\n",
       " ('opportunes', [1]),\n",
       " ('beaucoup', [1]),\n",
       " ('recul', [1]),\n",
       " ('afin', [1]),\n",
       " ('circonvenir', [1]),\n",
       " ('cette', [1]),\n",
       " ('inflexion', [1]),\n",
       " ('époque', [1]),\n",
       " ('recommande', [1]),\n",
       " ('essayer', [1]),\n",
       " ('somme', [1, 1]),\n",
       " ('stratégies', [1]),\n",
       " ('envisageables', [1]),\n",
       " ('même', [1]),\n",
       " ('facile', [1]),\n",
       " ('dualité', [1, 1]),\n",
       " ('situation', [1, 1]),\n",
       " ('négliger', [1]),\n",
       " ('gérer', [1]),\n",
       " ('certaines', [1]),\n",
       " ('synergies', [1]),\n",
       " ('optimales', [1]),\n",
       " ('parce', [1, 1]),\n",
       " ('nous', [1]),\n",
       " ('valons', [1]),\n",
       " ('bien', [1]),\n",
       " ('nonobstant', [1]),\n",
       " ('observée', [1]),\n",
       " ('inventorier', [1, 1]),\n",
       " ('modalités', [1]),\n",
       " ('temps', [1]),\n",
       " ('agir', [1]),\n",
       " ('baisse', [1]),\n",
       " ('confiance', [1]),\n",
       " ('présente', [1]),\n",
       " ('globalité', [1]),\n",
       " ('améliorations', [1]),\n",
       " ('pertinentes', [1]),\n",
       " ('très', [1]),\n",
       " ('attentivement', [1])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHUFFLE & SORT : autre méthode plus \"élégante\" en utilisant un dictionnaire\n",
    "from collections import defaultdict\n",
    "dico = defaultdict(list)\n",
    "\n",
    "liste = [couple for div in mapped for couple in div] #on regroupe tous les couples (clé, valeur) dans une seule liste\n",
    "\n",
    "list(map(lambda tup : dico[tup[0]].append(tup[1]), liste))\n",
    "list(dico.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actuelle', 2),\n",
       " ('afin', 1),\n",
       " ('agir', 1),\n",
       " ('améliorations', 1),\n",
       " ('attentivement', 1),\n",
       " ('avec', 2),\n",
       " ('avis', 2),\n",
       " ('baisse', 1),\n",
       " ('beaucoup', 1),\n",
       " ('bien', 1),\n",
       " ('certaines', 1),\n",
       " ('cette', 1),\n",
       " ('circonvenir', 1),\n",
       " ('concernant', 2),\n",
       " ('confiance', 1),\n",
       " ('conjoncturelle', 2),\n",
       " ('dualité', 2),\n",
       " ('envisageables', 1),\n",
       " ('essayer', 1),\n",
       " ('exclus', 3),\n",
       " ('facile', 1),\n",
       " ('faut', 2),\n",
       " ('fragilité', 1),\n",
       " ('globalité', 1),\n",
       " ('gérer', 1),\n",
       " ('hypothèses', 1),\n",
       " ('inflexion', 1),\n",
       " ('interdire', 1),\n",
       " ('inventorier', 2),\n",
       " ('matricielles', 1),\n",
       " ('modalités', 1),\n",
       " ('morosité', 1),\n",
       " ('même', 1),\n",
       " ('nonobstant', 1),\n",
       " ('nous', 1),\n",
       " ('négliger', 1),\n",
       " ('observée', 1),\n",
       " ('opportunes', 1),\n",
       " ('optimales', 1),\n",
       " ('organisations', 1),\n",
       " ('parce', 2),\n",
       " ('pertinentes', 1),\n",
       " ('prudence', 1),\n",
       " ('précisément', 1),\n",
       " ('présente', 1),\n",
       " ('recommande', 1),\n",
       " ('recul', 1),\n",
       " ('remémorer', 1),\n",
       " ('requise', 1),\n",
       " ('réalisables', 2),\n",
       " ('réorganiser', 1),\n",
       " ('simultanéité', 1),\n",
       " ('situation', 2),\n",
       " ('somme', 2),\n",
       " ('stratégies', 1),\n",
       " ('synergies', 1),\n",
       " ('temps', 1),\n",
       " ('toute', 1),\n",
       " ('très', 1),\n",
       " ('valons', 1),\n",
       " ('voulez', 2),\n",
       " ('vous', 2),\n",
       " ('égard', 1),\n",
       " ('époque', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REDUCE : ici c'est très simple puisqu'il s'agit de seulement sommer les valeurs de la liste\n",
    "#on aurait pu intégrer cette étape facilement dans le SHUFFLE & SORT mais ici on cherche à dissocier les différentes étapes pour bien comprendre\n",
    "def reducer(key, values):\n",
    "    sum_val = reduce(lambda x,y : x+y, values) #on peut utiliser directement sum(), je force juste un peu l'utilisation du reduce ici pour rester dans l'esprit\n",
    "    return (key, sum_val)\n",
    "\n",
    "reduced = list(map(lambda tup: reducer(tup[0], tup[1]), shuffled_sorted)) #le \"map\" utilisé ici correspond en fait à la parallélisation du traitement sur chaque clé=mot\n",
    "reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pour : finir moyenne de liste et temps d'éxecution**\n",
    "\n",
    "**Exo10:** à l'aide des fonctions ```map``` et ```reduce```, on va calculer la moyenne des éléments d'une liste. Et sans utiliser ```len()```...\n",
    ">1. créer une liste d'entiers aléatoires de taille 10^7\n",
    ">2. utiliser ```map``` et ```reduce``` pour caluler la moyenne sur cette liste\n",
    ">3. utiliser ```%%time``` pour mesurer le temps d'éxecution de ce calcul\n",
    ">4. découper la liste en 5 sous-listes de tailles égales\n",
    ">5. importer le module Pool de la libraire multiprocessing et l'utiliser pour paralléliser les calculs sur chaque sous-liste. L'idée est de définir par exemple une fonction MapReduce_average qui reprend votre méthode utilisée pour le calcul de la moyenne et utiliser pool.map(MapReduce_average, liste_splitée)\n",
    ">6. regarder avec %%time les différences de temps d'éxecution des 2 méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(1000, size=10**7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 ms, sys: 0 ns, total: 15.5 ms\n",
      "Wall time: 14.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499.6591571"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.37 s, sys: 6.64 ms, total: 4.37 s\n",
      "Wall time: 4.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499.6591571"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "a_mapped = map(lambda val : (val,1), a)\n",
    "a_reduce = reduce(lambda x,y : (x[0]+y[0],x[1]+y[1]), a_mapped)\n",
    "a_reduce[0]/a_reduce[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 16, 379, 665, ..., 126, 222, 481]),\n",
       " array([306, 375, 726, ..., 380, 568, 471]),\n",
       " array([822, 374, 728, ...,  67, 384, 320]),\n",
       " array([436, 972, 507, ..., 490, 784,  40]),\n",
       " array([949, 414, 887, ..., 464, 924, 121])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = int(2*10**6)\n",
    "a_split = [a[k*step:(k+1)*step] for k in range(5)]\n",
    "a_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "pool = Pool(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mr_avg(liste):\n",
    "    mapped = map(lambda i : (i,1), liste)\n",
    "    return reduce(lambda x,y : (x[0]+y[0],x[1]+y[1]), mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.8 ms, sys: 118 ms, total: 160 ms\n",
      "Wall time: 2.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499.6591571"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mapped = pool.map(mr_avg,a_split)\n",
    "reduced = reduce(lambda x,y : (x[0]+y[0],x[1]+y[1]), mapped)\n",
    "reduced[0]/reduced[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Supplément**\n",
    "\n",
    "**Exo11:** Calculer en utilisant le paradigme MapReduce le produit d'une matrice M avec un vecteur V.  \n",
    "Ça peut paraître inutile mais cette opération est derrière l'algorithme du PageRank de Google, c'est d'ailleurs en partie pour ce calcul que MapReduce a été conçu. Dans ce cas, la dimension du problème est le nombre de pages web indexées, soit clairement un problème de Big Data.  \n",
    "Par ailleurs, on l'a vu dans la régression linéaire notamment mais pas uniquement, ce produit $matrice*vecteur$ est omniprésent dans les problèmes d'optimisation aussi.\n",
    ">*Quelques indications:*\n",
    ">0. commencer par vous remettre dans le bain en revoyant comment on calcul un produit matriciel et plus exactement un produit $matrice*vecteur$\n",
    ">1. générer une matrice aléatoire $M$ de taille (5,6) par exemple et un vecteur de taille 6\n",
    ">2. transformer votre matrice $M$ en une liste de triplet $(i,j,m_{ij})$\n",
    ">3. étape map : on peut choisir comme clé le numéro de ligne et l'étape map consistera donc à passer du triplet $(i,j,m_{ij})$ au couple $(i,m_{ij}*v_j)$\n",
    ">4. étape shuffle&sort : il faut regrouper les couples (clé, valeur) en (clé, liste_de_valeurs), la clé étant ici l'indice de ligne $i$\n",
    ">5. étape réduce : agréger les résultats en les sommant\n",
    "\n",
    "*Pour aller plus loin:* cette solution marche convenablement lorsque chaque noeud a la capacité de stocker $V$ localement mais que faire si $V$ est trop grand ? Vous pouvez mettre en pratique votre solution avec les mêmes $M$ et $V$ que précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 6 2 5 1 4]\n",
      " [8 5 8 7 7 2]\n",
      " [5 6 2 9 8 1]\n",
      " [9 9 3 0 5 2]\n",
      " [4 3 8 8 1 1]]\n",
      "[6 4 7 6 2 6]\n"
     ]
    }
   ],
   "source": [
    "#génération matrice\n",
    "M = np.random.randint(10, size=(5,6))\n",
    "V = np.random.randint(10, size=6)\n",
    "print(M,V, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 5),\n",
       " (0, 1, 6),\n",
       " (0, 2, 2),\n",
       " (0, 3, 5),\n",
       " (0, 4, 1),\n",
       " (0, 5, 4),\n",
       " (1, 0, 8),\n",
       " (1, 1, 5),\n",
       " (1, 2, 8),\n",
       " (1, 3, 7),\n",
       " (1, 4, 7),\n",
       " (1, 5, 2),\n",
       " (2, 0, 5),\n",
       " (2, 1, 6),\n",
       " (2, 2, 2),\n",
       " (2, 3, 9),\n",
       " (2, 4, 8),\n",
       " (2, 5, 1),\n",
       " (3, 0, 9),\n",
       " (3, 1, 9),\n",
       " (3, 2, 3),\n",
       " (3, 3, 0),\n",
       " (3, 4, 5),\n",
       " (3, 5, 2),\n",
       " (4, 0, 4),\n",
       " (4, 1, 3),\n",
       " (4, 2, 8),\n",
       " (4, 3, 8),\n",
       " (4, 4, 1),\n",
       " (4, 5, 1)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transformation en liste de triplets\n",
    "M_liste = [(i,j,M[i,j]) for i in range(M.shape[0]) for j in range(M.shape[1])]\n",
    "M_liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 30),\n",
       " (0, 24),\n",
       " (0, 14),\n",
       " (0, 30),\n",
       " (0, 2),\n",
       " (0, 24),\n",
       " (1, 48),\n",
       " (1, 20),\n",
       " (1, 56),\n",
       " (1, 42),\n",
       " (1, 14),\n",
       " (1, 12),\n",
       " (2, 30),\n",
       " (2, 24),\n",
       " (2, 14),\n",
       " (2, 54),\n",
       " (2, 16),\n",
       " (2, 6),\n",
       " (3, 54),\n",
       " (3, 36),\n",
       " (3, 21),\n",
       " (3, 0),\n",
       " (3, 10),\n",
       " (3, 12),\n",
       " (4, 24),\n",
       " (4, 12),\n",
       " (4, 56),\n",
       " (4, 48),\n",
       " (4, 2),\n",
       " (4, 6)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAP\n",
    "def prod1(triplet):\n",
    "    i,j,Mij = triplet\n",
    "    return i,Mij*V[j]\n",
    "\n",
    "mapped = list(map(prod1, M_liste))\n",
    "mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [30, 24, 14, 30, 2, 24]),\n",
       " (1, [48, 20, 56, 42, 14, 12]),\n",
       " (2, [30, 24, 14, 54, 16, 6]),\n",
       " (3, [54, 36, 21, 0, 10, 12]),\n",
       " (4, [24, 12, 56, 48, 2, 6])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHUFFLE AND SORT\n",
    "from collections import defaultdict\n",
    "dico = defaultdict(list)\n",
    "list(map(lambda tup : dico[tup[0]].append(tup[1]), mapped))\n",
    "shuffled = list(dico.items())\n",
    "shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 124), (1, 192), (2, 144), (3, 133), (4, 148)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REDUCE\n",
    "def reducer(key, values):\n",
    "    return (key, sum(values))\n",
    "\n",
    "reduced = list(map(lambda tup: reducer(tup[0], tup[1]), shuffled))\n",
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124, 192, 144, 133, 148]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#si on veut représenter le vecteur sous forme de liste:\n",
    "[x[1] for x in reduced]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pour aller plus loin:* cas où $V$ ne peut pas être stocké entièrement dans les noeuds\n",
    "\n",
    "La solution est assez triviale en théorie: puisque $V$ ne rentre pas dans un noeud, il faut le découper de sorte que chaque noeud s'occupe d'une partie du calcul.  \n",
    "**Attention** derrière la simplicité de cette solution, il y a toutefois une petite subtilité. En effet, puisqu'on découpe $V$, il faut aussi découper $M$ de manière cohérente.\n",
    "\n",
    "Dans notre exemple $M$ est de taille (5,6) et $V$ et de taille 6 c'est-à-dire en fait de taille (6,1).  \n",
    "On découpe $V$ horizontalement en trois vecteurs de taille (2,1).  \n",
    "Il faut donc pour pouvoir faire le produit découper $M$ \"verticalement\" en trois matrices de tailles (5,2).\n",
    "Ensuite on aura plus qu'à regrouper les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 6 2 5 1 4]\n",
      " [8 5 8 7 7 2]\n",
      " [5 6 2 9 8 1]\n",
      " [9 9 3 0 5 2]\n",
      " [4 3 8 8 1 1]]\n",
      "[6 4 7 6 2 6]\n"
     ]
    }
   ],
   "source": [
    "print(M)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[5, 6],\n",
       "         [8, 5],\n",
       "         [5, 6],\n",
       "         [9, 9],\n",
       "         [4, 3]]),\n",
       "  array([6, 4])),\n",
       " (array([[2, 5],\n",
       "         [8, 7],\n",
       "         [2, 9],\n",
       "         [3, 0],\n",
       "         [8, 8]]),\n",
       "  array([7, 6])),\n",
       " (array([[1, 4],\n",
       "         [7, 2],\n",
       "         [8, 1],\n",
       "         [5, 2],\n",
       "         [1, 1]]),\n",
       "  array([2, 6]))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_splitted = [M[:,0:2], M[:,2:4],  M[:,4:6]]\n",
    "V_splitted = [V[0:2], V[2:4], V[4:6]]\n",
    "\n",
    "#on peut recréer un couple sous-matrice/sous-vecteur qui correspond à l'information stockée dans chaque noeud du cluster\n",
    "MV = [(M_splitted[k], V_splitted[k]) for k in range(3)]\n",
    "MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(0, 0, 5),\n",
       "   (0, 1, 6),\n",
       "   (1, 0, 8),\n",
       "   (1, 1, 5),\n",
       "   (2, 0, 5),\n",
       "   (2, 1, 6),\n",
       "   (3, 0, 9),\n",
       "   (3, 1, 9),\n",
       "   (4, 0, 4),\n",
       "   (4, 1, 3)],\n",
       "  [6, 4]),\n",
       " ([(0, 0, 2),\n",
       "   (0, 1, 5),\n",
       "   (1, 0, 8),\n",
       "   (1, 1, 7),\n",
       "   (2, 0, 2),\n",
       "   (2, 1, 9),\n",
       "   (3, 0, 3),\n",
       "   (3, 1, 0),\n",
       "   (4, 0, 8),\n",
       "   (4, 1, 8)],\n",
       "  [7, 6]),\n",
       " ([(0, 0, 1),\n",
       "   (0, 1, 4),\n",
       "   (1, 0, 7),\n",
       "   (1, 1, 2),\n",
       "   (2, 0, 8),\n",
       "   (2, 1, 1),\n",
       "   (3, 0, 5),\n",
       "   (3, 1, 2),\n",
       "   (4, 0, 1),\n",
       "   (4, 1, 1)],\n",
       "  [2, 6])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transformation en liste de triplets\n",
    "def triplets(block):\n",
    "    M = block[0]\n",
    "    V = block[1]\n",
    "    return [(i,j,M[i,j]) for i in range(M.shape[0]) for j in range(M.shape[1])], list(V)\n",
    "\n",
    "MV_triplets = list(map(triplets, MV))\n",
    "MV_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 30),\n",
       "  (0, 24),\n",
       "  (1, 48),\n",
       "  (1, 20),\n",
       "  (2, 30),\n",
       "  (2, 24),\n",
       "  (3, 54),\n",
       "  (3, 36),\n",
       "  (4, 24),\n",
       "  (4, 12)],\n",
       " [(0, 14),\n",
       "  (0, 30),\n",
       "  (1, 56),\n",
       "  (1, 42),\n",
       "  (2, 14),\n",
       "  (2, 54),\n",
       "  (3, 21),\n",
       "  (3, 0),\n",
       "  (4, 56),\n",
       "  (4, 48)],\n",
       " [(0, 2),\n",
       "  (0, 24),\n",
       "  (1, 14),\n",
       "  (1, 12),\n",
       "  (2, 16),\n",
       "  (2, 6),\n",
       "  (3, 10),\n",
       "  (3, 12),\n",
       "  (4, 2),\n",
       "  (4, 6)]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAP\n",
    "def mapper(block):\n",
    "    M = block[0]\n",
    "    V = block[1]\n",
    "    return [(triplet[0], triplet[2]*V[triplet[1]]) for triplet in M]\n",
    "    \n",
    "mapped = list(map(mapper, MV_triplets))\n",
    "mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, [30, 24]), (1, [48, 20]), (2, [30, 24]), (3, [54, 36]), (4, [24, 12])],\n",
       " [(0, [14, 30]), (1, [56, 42]), (2, [14, 54]), (3, [21, 0]), (4, [56, 48])],\n",
       " [(0, [2, 24]), (1, [14, 12]), (2, [16, 6]), (3, [10, 12]), (4, [2, 6])]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SHUFFLE AND SORT\n",
    "def shfld(block):\n",
    "    dico = defaultdict(list)\n",
    "    list(map(lambda tup : dico[tup[0]].append(tup[1]), block))\n",
    "    return list(dico.items())\n",
    "\n",
    "shuffled = list(map(shfld, mapped))\n",
    "shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 54), (1, 68), (2, 54), (3, 90), (4, 36)],\n",
       " [(0, 44), (1, 98), (2, 68), (3, 21), (4, 104)],\n",
       " [(0, 26), (1, 26), (2, 22), (3, 22), (4, 8)]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REDUCE\n",
    "def reducer(block):\n",
    "    return list(map(lambda tup: (tup[0], sum(tup[1])), block))\n",
    "\n",
    "reduced = list(map(reducer, shuffled))\n",
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 124), (1, 192), (2, 144), (3, 133), (4, 148)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On réitère SHUFFLE AND SORT + REDUCE sur la liste qui regroupe les résultats de chaque noeud\n",
    "liste = [item for sublist in reduced for item in sublist]\n",
    "reducer(shfld(liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124, 192, 144, 133, 148]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pour avoir le vecteur final\n",
    "[c[1] for c in reducer(shfld(liste))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
