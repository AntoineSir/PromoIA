{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dans le dataset initial (5000_movies.csv)**, il y a beaucoup de valeurs manquantes dans `gross` et dans `budget` donc imputation délicate mais comme on veut garder ces variables, on va alors supprimer les lignes. Avant cette suppression on peut essayer de scraper IMDB pour obtenir des informations supplémentaires. Pour cela, un petit notebook séparé dans le même dossier permet de récupérer les données supplémentaires éventuelles, de les ajouter dans les colonnes `gross` et `budget` du dataframe `data`. Comme l'éxecution est un peu longue, on va sauvegarder ce dataframe dans un nouveau csv pour ne pas avoir à le refaire à chaque fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_h3GW7YI3SY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('5000_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping des données 'gross'\n",
    "def scrap_gross(row):\n",
    "    link = row['movie_imdb_link']\n",
    "    if np.isnan(row['gross']):\n",
    "        page = urlopen(link).read()\n",
    "        soup = BeautifulSoup(page)\n",
    "        for h4 in soup.find_all('h4', {'class':'inline'}):\n",
    "            if \"Gross USA:\" in h4:\n",
    "                return float(h4.next_sibling.strip().replace(\"$\",\"\").replace(\",\",\"\"))\n",
    "    else:\n",
    "        return row['gross']\n",
    "\n",
    "data['gross'] = data.apply(scrap_gross, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping des données 'budget'\n",
    "def scrap_budget(row):\n",
    "    link = row['movie_imdb_link']\n",
    "    if np.isnan(row['budget']):\n",
    "        page = urlopen(link).read()\n",
    "        soup = BeautifulSoup(page)\n",
    "        for h4 in soup.find_all('h4', {'class':'inline'}):\n",
    "            if \"Budget:\" in h4:\n",
    "                return float(h4.next_sibling.strip().replace(\"$\",\"\").replace(\",\",\"\").replace(\"EUR\",\"\")) #il faudrait convertir la valeur € en $ pour bien faire...\n",
    "    else:\n",
    "        return row['budget']\n",
    "    \n",
    "data['budget'] = data.apply(scrap_budget, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrement du dataframe en csv\n",
    "data.to_csv('5000_movies_bis.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bita52171538b9a4ca5b21bfc37812f360f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
