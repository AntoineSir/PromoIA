{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les SVM : première rencontre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Cas linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simuler un ensemble d’entraînement de dimension 2 linéairement séparable, c'est-à-dire que l'on peut séparer par une droite. Il devra être composé de 100 observations avec 2 caractéristiques chacune (*indication : on peut prendre par exemple y=1 pour x1 > 0.5*)\n",
    "- Afficher cet ensemble en colorant par label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.rand(100,2)\n",
    "y = X[:,0] > 0.5\n",
    "plt.scatter(X[:,0],X[:,1], c = y, s = 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrainer un classifieur SVM linéaire (LinearSVC) et calculer l'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()\n",
    "svc.fit(X,y)\n",
    "print(\"accuracy:\",svc.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Faire varier le paramètre C pour voir son effet sur le modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in [10**x for x in range(-5,5)]:\n",
    "    svc = LinearSVC(C=C)\n",
    "    svc.fit(X,y)\n",
    "    plt.title('C = ' + str(C) + ' et score = ' + str(svc.score(X,y)))\n",
    "    print(\"accuracy:\",svc.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Faire un graphique avec l'ensemble de décision en utilisant une fonction `frontiere` à définir (le graphique doit donc représenter les points et les 2 espaces séparés par la frontière de décision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frontiere(clf, X, y):\n",
    "    h = 0.002\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s = 100)\n",
    "    plt.title('score : ' + str(clf.score(X,y)))\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontiere(svc,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sur cet ensemble, ajouter du bruit aux y (par exemple avec une probabilité p, yi = 1-yi)\n",
    "- Afficher l'ensemble, entrainer un SVM linéaire (LinearSVC) et faire varier le paramètre C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.rand(100,2)\n",
    "y = X[:,0] > 0.5\n",
    "\n",
    "lignes_bruitees = np.random.choice(range(len(y)), 10)\n",
    "y[lignes_bruitees] = 1 - y[lignes_bruitees]\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1], c = y, s = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in [10**x for x in range(-5,5)]:\n",
    "    svc = LinearSVC(C=C)\n",
    "    svc.fit(X,y)\n",
    "    frontiere(svc,X,y)\n",
    "    plt.title('C = ' + str(C) + ' et score = ' + str(svc.score(X,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Cas non linéaire : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Générer des données d'entrainement non linéairement séparable puis les afficher avec les couleurs. On peut utiliser : \n",
    ">- from sklearn.datasets import make_moons \n",
    ">- X, y = make_moons(noise = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(noise = 0.1, random_state=1)\n",
    "plt.scatter(X[:,0],X[:,1], c = y, s = 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Générer de la même manière un échantillon de données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_test, y_test = make_moons(noise = 0.1, random_state=321)\n",
    "plt.scatter(X_test[:,0],X_test[:,1], c = y_test, s = 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entraîner un SVM avec les différents noyaux possibles et avec différentes valeurs de $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#kernel = 'linear'\n",
    "for C in [10**x for x in range(-3,5)]:\n",
    "    svc = SVC(C=C, kernel='linear')\n",
    "    svc.fit(X,y)\n",
    "    print(\"score entrainement:\",svc.score(X,y), \"et score test:\", svc.score(X_test,y_test))\n",
    "    frontiere(svc,X,y)\n",
    "    plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1], c = 'green', s = 200, marker='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#kernel = 'poly'\n",
    "for C in [10**x for x in range(-3,5)]:\n",
    "    svc = SVC(C=C, kernel='poly', degree = 3, coef0 = 1)\n",
    "    svc.fit(X,y)\n",
    "    print(\"score entrainement:\",svc.score(X,y), \"et score test:\", svc.score(X_test,y_test))\n",
    "    frontiere(svc,X,y)\n",
    "    plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1], c = 'green', s = 200, marker='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#kernel = 'rbf'\n",
    "for C in [10**x for x in range(-3,5)]:\n",
    "    svc = SVC(C=C, kernel='rbf')\n",
    "    svc.fit(X,y)\n",
    "    print(\"score d'entrainement:\",svc.score(X,y), \". score de test:\", svc.score(X_test,y_test))\n",
    "    frontiere(svc,X,y)\n",
    "    plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1], c = 'green', s = 200, marker='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#kernel = 'sigmoid'\n",
    "for C in [10**x for x in range(-3,5)]:\n",
    "    svc = SVC(C=C, kernel='sigmoid', coef0 = 1, gamma = 0.01)\n",
    "    svc.fit(X,y)\n",
    "    print(\"score d'entrainement:\",svc.score(X,y), \". score de test:\", svc.score(X_test,y_test))\n",
    "    frontiere(svc,X,y)\n",
    "    plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1], c = 'green', s = 200, marker='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = X[n_samples / 2:]\n",
    "y_train = y[n_samples / 2:]\n",
    "\n",
    "X_valid = X[:n_samples / 2]\n",
    "y_valid = y[:n_samples / 2]\n",
    "\n",
    "print(\"X_train : {} exemples, avec 8*8 = {} features.\".format(X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Une petite application sur les données de digits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Charger le jeu de données digits disponible dans sklearn\n",
    ">- utiliser la fonction load_digits\n",
    ">- regarder ce que contient le dataset\n",
    ">- enregistrer les images dans une variables images\n",
    ">- créer la matrice X à l'aide d'un reshape\n",
    ">- créer le vecteur y à partir de l'attribut targets du dataset\n",
    "- Afficher 8 images prises au hasard dans le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "images = digits.images\n",
    "n_samples = len(digits.images)\n",
    "\n",
    "X = images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "idx_plt=1\n",
    "for image in images[np.random.choice(range(n_samples),8)]:\n",
    "    plt.subplot(2,4,idx_plt)\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    idx_plt+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Découper le dataset en échantillons d'entraînement et de test\n",
    "- Entrainer un kNN, une régression logistique et un SVM\n",
    "- Comparer ces modèles\n",
    "- Utiliser GridSearchCV pour affiner le choix des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'knn': KNeighborsClassifier(3),\n",
    "    'reglog': LogisticRegression(),\n",
    "    'svc': SVC(gamma=0.001, C=1, kernel='rbf')\n",
    "}\n",
    "\n",
    "for k,v in models.items():\n",
    "    model = v\n",
    "    model.fit(X_train,y_train)\n",
    "    print('score de',k,model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
