{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Une régression logistique sur MNIST pour la reconnaissance de chiffres manuscrits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger les données du MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs manières de faire, certaines plus fastidieuses que d'autres, une petite recherche Google vous donnera toutes les informations nécessaires. Moi je vais me contenter de l'importer depuis keras.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape,X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_images(nb_images_a_afficher, nb_colonnes=5):\n",
    "    nb_lignes = nb_images_a_afficher//nb_colonnes+1\n",
    "\n",
    "    plt.figure(figsize=(20,5*nb_lignes))\n",
    "    for index, (image, label) in enumerate(zip(X_train[0:nb_images_a_afficher], y_train[0:nb_images_a_afficher])):\n",
    "        plt.subplot(nb_lignes, nb_colonnes, index + 1)\n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        plt.title('Training: %i\\n' % label, fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afficher_images(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification du shape de X_train et X_test pour avoir un array de dimension 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000,-1)\n",
    "X_test = X_test.reshape(10000,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.import du modèle\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# 2.instanciation du modèle\n",
    "reglog = LogisticRegression(solver='lbfgs')\n",
    "# 3.entrainement du modèle \n",
    "reglog.fit(X_train, y_train)\n",
    "# 4.prédictions\n",
    "reglog.predict(X_test[0].reshape(1,-1)) # de un élément\n",
    "reglog.predict(X_test[0:10]) # de plusieurs éléments\n",
    "y_pred = reglog.predict(X_test) # de tout le set de test\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La méthdode scor du modèle renvoie l'accuracy\n",
    "score = reglog.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision et recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage sous forme de dataframe\n",
    "cm = pd.DataFrame(cm, columns=['prédit ' + str(_) for _ in reglog.classes_])\n",
    "cm.index = ['vrai ' + str(_) for _ in reglog.classes_]\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage sous forme de graphique avec sns.heatmap\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Reds');\n",
    "plt.ylabel('Vrai label');\n",
    "plt.xlabel('Label prédit');\n",
    "all_sample_title = 'Accuracy Score: {:.3f}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des images qui ont été mal classées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayer de faire d'afficher les images quion été mal classées avec leurs labels prédit et vrai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal_classees = []\n",
    "for index, (pred, vrai) in enumerate(zip(y_pred, y_test)):\n",
    "    if pred != vrai: \n",
    "        mal_classees.append(index)\n",
    "len(mal_classees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_colonnes=5\n",
    "nb_images_a_afficher = 20\n",
    "nb_lignes = nb_images_a_afficher//nb_colonnes+1\n",
    "\n",
    "plt.figure(figsize=(20,5*nb_lignes))\n",
    "for i in range(nb_images_a_afficher):\n",
    "    idx_image = mal_classees[i]\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(np.reshape(X_test[idx_image], (28,28)), cmap='inferno')\n",
    "    plt.title('Prédit {} alors que {}'.format(y_pred[idx_image], y_test[idx_image]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance du modèle en fonction de la taille du trainin set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (24,16));\n",
    "\n",
    "sample_size = [100, 1000, 3000, 60000]\n",
    "for i,s in enumerate(sample_size):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    X = X_train[:s].reshape(s,-1)\n",
    "    y = y_train[:s]\n",
    "    reglog.fit(X, y)\n",
    "    pred = reglog.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    #cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, cmap = 'Reds', cbar = False)\n",
    "    accuracyString = 'Score sur un training set de taille {:g}: {:.3f}'.format(s, reglog.score(X_test, y_test)) \n",
    "    plt.title(accuracyString, size = 20)\n",
    "    plt.xlabel('Label prédit', fontsize = 12)\n",
    "    plt.ylabel('Vrai label', fontsize = 12);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
