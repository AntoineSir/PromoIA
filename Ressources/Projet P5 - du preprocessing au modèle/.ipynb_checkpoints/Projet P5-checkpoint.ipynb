{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bd8dOd6qOZYV"
   },
   "source": [
    "# **Projet P5 - une solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyS7Q6eAO_C4"
   },
   "source": [
    "Analyse du jeu de données [Census Dataset](https://archive.ics.uci.edu/ml/datasets/census+income) à partir du dépot officiel : UCI Machine Learning Repository.  \n",
    "\n",
    "Il y a 3 datasets:\n",
    "- Le training set : [adult.data](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data)\n",
    "- La description du dataset : [adult.names](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names)\n",
    "- Le test set : [adult.test](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2oUOp-mixIv"
   },
   "source": [
    "## **1. Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_h3GW7YI3SY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer,make_column_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YVVEtK34i4bV"
   },
   "source": [
    "## **2. Charger les données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut télécharger les données _\"à la main\"_ mais on peut aussi utiliser le module requests pour aller les chercher directement sur UCI Machine Learning Repository. L'intérêt est de pouvoir mettre à jour directement les données s'il y avait des modifications lorsqu'on réexécute le notebook. Intérêt limité dans notre cas puisque le jeu date de 1996 et n'est plus vraiment mis à jour. C'est toujours un bon exercice de le faire !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La cellule est commentée car les données ont été chargées récemment ce n'est pas la peine de recommencer\n",
    "\"\"\"def load_data(path, urls):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    for url in urls:\n",
    "        data = requests.get(url).content\n",
    "        filename = os.path.join(path, os.path.basename(url))\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(data)\n",
    "\n",
    "urls = [\"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\",\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"]\n",
    "\n",
    "load_data('data', urls)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrFjx7nUs08M"
   },
   "source": [
    "**Quelques remarques :**\n",
    ">- Les jeu de données n'ont pas de noms de colonnes par défaut, il faut donc les ajouter manuellement. On les récupère dans le data.names\n",
    ">- Comme évoqué, certaines observations on des espaces avant et après les valeurs. On peut passer une expression régulière pour le paramètre **sep** de la fonction [read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). \" \\*, \\*\"\n",
    ">- Les valeurs manquantes sont indiquées par **'?'**. une fois qu'on l'a remarqué on peut fixer le paramètre **na_values** \n",
    ">- Le jeu de données test contient une première ligne bizarre donc on peut ajouter le paramètre **skiprows=1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "P33SbAllaHLf",
    "outputId": "3f130f3c-3190-4a0b-d3af-1e40dd0c41e1"
   },
   "outputs": [],
   "source": [
    "columns = [\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\",\n",
    "           \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"]\n",
    "\n",
    "train_data = pd.read_csv('data/adult.data', names = columns, sep=' *, *', na_values='?', engine='python')\n",
    "test_data = pd.read_csv('data/adult.test', names = columns, sep=' *, *', skiprows =1, na_values='?', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "Kh6uDBUC-xy1",
    "outputId": "6283391a-319c-46bd-c15e-82b845424584"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "AzzXNMNL-xG7",
    "outputId": "5636fde5-c49b-4557-9e94-ed9f56961193"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION** on peut remarquer que la colonne *income* de test_data a un \".\" à la fin. Il ne faudra pas l'oublier au moment d'encoder la variable y en 0-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nNnaPdClkRvC"
   },
   "source": [
    "## **3. Analyse exploratoire**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8xSbpLqkVon"
   },
   "source": [
    "### **Informations générales sur le dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kp09FXSZwH3z"
   },
   "source": [
    "On cherche les valeurs manquantes qu'il va falloir au choix supprimer ou imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "kba0Hvcb4uW9",
    "outputId": "ce2f9f82-09ea-4fc9-d043-6019008e07f3"
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,8))\n",
    "sns.heatmap(train_data.isnull(), yticklabels=False, cbar=False, cmap='inferno', ax=ax[0]);\n",
    "sns.heatmap(test_data.isnull(), yticklabels=False, cbar=False, cmap='inferno', ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSA95wuHwZbl"
   },
   "source": [
    "**Quelques remarques**\n",
    ">- Nombre d'observations : **32561** dans le train set et **16281** dans le test set\n",
    ">- Présence de variables catégoriques et numériques\n",
    ">- Les colonnes **workClass**, **occupation**, **native_country** ont des valeurs manquantes\n",
    "\n",
    "On va pas faire l'imputation des valeurs manquantes dans cette étape mais directement dans la Pipeline de preprocessing que l'on créera un peu plus loin. Ce n'est pas du tout obligatoire et on pourrait choisir de s'en occuper ici et maintenant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Un peu de visualisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde maintenant plus en détail nos variables : leur distribution, leur plage de valeurs, des éventuelles corrélations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOcQwld3ZR0S"
   },
   "source": [
    "#### **Cas des variables numériques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TtzYigO5xwi3"
   },
   "source": [
    "On peut sélectionner les valeurs numériques avec la fonction [select_dtypes](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.select_dtypes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "LWdg0QamqEdi",
    "outputId": "303b5a58-077f-4a72-cfae-b2708737fd52"
   },
   "outputs": [],
   "source": [
    "varnum = train_data.select_dtypes(include=['int'])\n",
    "varnum.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSA95wuHwZbl"
   },
   "source": [
    "**Quelques remarques**\n",
    "> Les variables *age*, *education_num* et *hours_per_week* sont suffisament explicites. Pour les autres :\n",
    ">- *fnlwgt* : poids d'échantillonage, on ne s'en servira pas ici\n",
    ">- *capital_gain/loss* : revenu ou perte dûs à d'autres sources que le salaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "colab_type": "code",
    "id": "m6IDOUpy2Y_t",
    "outputId": "b88a9979-78cb-4447-e8f8-ae7de357c34d"
   },
   "outputs": [],
   "source": [
    "varnum.hist(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "JJurqE1f3UPl",
    "outputId": "562bab24-7a77-4d8f-b153-e9aa95b6b85e"
   },
   "outputs": [],
   "source": [
    "varnum.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSA95wuHwZbl"
   },
   "source": [
    "**Quelques remarques**\n",
    ">- Pas de valeurs manquantes pour les variables numériques\n",
    ">- Échelles très différentes et donc nécessité de passer par l'étape *feature scaling*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ncrvd9RUtDw2"
   },
   "source": [
    "#### **Cas des variables catégoriques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gunQra7ckaaQ",
    "outputId": "5b617f5d-f22f-4462-e0b3-4e221bf02764"
   },
   "outputs": [],
   "source": [
    "varcat = train_data.select_dtypes(include=['object'])\n",
    "varcat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "srcQz7Lg5BkB",
    "outputId": "c15708c3-58b6-45e6-95b8-b1e2f758ffca"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22,28))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.3)\n",
    "for i in range(varcat.shape[1]-1):\n",
    "    var = varcat.columns[i]\n",
    "    fig.add_subplot(4,2,i+1)\n",
    "    sns.countplot(y=var, hue='income', data=varcat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSA95wuHwZbl"
   },
   "source": [
    "**Quelques remarques**\n",
    "> Les variables *workClass*, *occupation* et *native_country* ont des valeurs manquantes : pour simplifier, on va imputer la valeur la plus fréquente. Une stratégie pourrait être de mettre en place en kNN en prenant comme train set les données complètes et affecter à chaque individu le mode des plus proches voisins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Nettoyage des datasets et création de X et y**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a choisi de ne pas conserver : *education* et *fnlwgt*. Par ailleurs, on peut ici construire notre matrice X des variables indépendantes et y le vecteur contenant la variable prédite. De plus, notre variable prédite prend 2 valeurs : \"<=50K\" et \">50K\". On va recoder donc cette variable en 0 et 1 directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"income\"].apply(lambda x:0 if x=='<=50K' else 1)\n",
    "y_test = test_data[\"income\"].apply(lambda x:0 if x=='<=50K.' else 1) #on n'oublie pas le \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['fnlwgt', 'education', 'income'], axis=1)\n",
    "X_test = test_data.drop(['fnlwgt', 'education', 'income'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvjQA0Be3Uzh"
   },
   "source": [
    "## **4. Pipeline pour le preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EQnBD5h7zsL"
   },
   "source": [
    "Il va falloir gérer différement les valeurs catégoriques et numériques. Les variables numériques doivent être *\"mises à l'échelle\"* alors que les variables catégoriques doivent être encodées en dummies.\n",
    "\n",
    "Comme évoqué, on peut utiliser pour ces enchaînements de processus un [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). Parfois, on peut aussi avoir besoin de construire nous-même nos *transformers* qui pourront être utilisés directement dans un Pipeline mais ce ne devrait pas être le cas ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mukeNstn--eS"
   },
   "source": [
    "Pour les variables numériques, il n'y a pas d'imputation à faire donc on a juste à utiliser un scaler (StandardScaler ou RobustScaler selon la décision prise). En revanche pour les variables catégoriques, il faut d'abord imputer les valeurs manquantes puis encoder numériquement les variables. On va donc d'abord créer une Pipeline pour la gestion des variables catégoriques qu'on pourra ensuite intégrer dans un objet de la classe ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suoFirzK55IR"
   },
   "outputs": [],
   "source": [
    "# la Pipeline pour les variables catégoriques\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first')) #handle_unknown='ignore' paramètre pour ignore les nouvelles modalités s'il y en a dans le test set\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", StandardScaler(), make_column_selector(dtype_include=np.number)),\n",
    "    (\"cat\", cat_pipe, make_column_selector(dtype_exclude=np.number))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajuste notre proprecessor sur X_train et on transforme ensuite X_train et X_test avec le même preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor appliqué aux données X_train et X_test\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wdy7WaYV4TXp"
   },
   "source": [
    "## **5. Entraînement du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglog = LogisticRegression(solver='liblinear', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eatCoCzaDHGs",
    "outputId": "4c2909ea-4d70-4405-b465-43290a4c89ce"
   },
   "outputs": [],
   "source": [
    "reglog.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PAnOIVEwVejs",
    "outputId": "235bac39-66d7-410f-e990-0d909794f384"
   },
   "outputs": [],
   "source": [
    "# On peut aussi faire une nouvelle pipeline contenant le processor + estimator \n",
    "reglog2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', max_iter=1000))\n",
    "])\n",
    "\n",
    "# On ajuste ensuite cette pipeline sur X_train\n",
    "reglog2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9V6q50qi4apQ"
   },
   "source": [
    "## **6. Évaluation du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train =', reglog.score(X_train_processed,y_train), 'et test =', reglog.score(X_test_processed,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train =', reglog2.score(X_train,y_train), 'et test =', reglog2.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,reglog.predict(X_test_processed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on va vraisemblablement tester plusieurs modèles et les évaluer on peut définir une fonction qui affiche un certain nombre d'informations et de graphes pour évaluer un modèle de classification donné. On pourra y mettre :\n",
    "- les mesures de l'accuracy, précision et recall\n",
    "- la matrice de confusion\n",
    "- la courbe ROC avec l'AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    proba_1 = model.predict_proba(X_test_processed)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, proba_1, pos_label=1, drop_intermediate=False)\n",
    "    aucf = auc(fpr, tpr)\n",
    "    cm = confusion_matrix(y_pred, y_test)\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    precision, rappel = precision_recall_fscore_support(y_test, y_pred, pos_label=1, average='macro')[0:2]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18,8))\n",
    "    ax1.plot([0, 1], [0, 1], 'k--')\n",
    "    ax1.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
    "    ax1.set_title('Courbe ROC')\n",
    "    ax1.text(0.5, 0.3, \"plus mauvais que\\nle hasard dans\\ncette zone\")\n",
    "    ax1.legend()\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=0.5, cmap=\"YlGnBu\", ax=ax2)\n",
    "    ax2.set_xlabel('Classes prédites')\n",
    "    ax2.set_ylabel('Classes réelles')\n",
    "\n",
    "    plt.suptitle(\"Accuracy = {:0.5} ; Precision = {:0.5} ; Rappel = {:0.5}\".format(accuracy,precision,rappel), fontsize = 15 )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(reglog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEYzV5EIF_VV"
   },
   "source": [
    "## **7. Validation Croisée**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKEGAx1BGItM"
   },
   "source": [
    "On va utiliser une validation croisée ave la méthode [StratifiedKFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) et [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) pour calculer le score sur chaque découpage de la validation croisée. Le paramètre **cv** détermine la méthode utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dnc0j6aNGPxJ",
    "outputId": "9cbe1746-7e52-4325-a57f-750dc18c43ea"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(reglog, X_train_processed, y_train, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nDa6q_oX4faX"
   },
   "source": [
    "## **8. Affinage des hyperparamètres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSN3-zqAb6uX"
   },
   "source": [
    "Les paramètres par défaut de la régression logistique sont les suivants :  \n",
    "LogisticRegression(*C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False*)\n",
    "          \n",
    "On peut utiliser la validation croisée et plus particulièrement la classe [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) pour affiner les hyperparamètres en testant le modèle pour différentes valeurs de ces paramètres que l'on spécifie.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPDFSirs3TvK"
   },
   "outputs": [],
   "source": [
    "# On crée notre liste d'hyperparamètres à tester sous forme de dictionnaire qui sera ensuite passé en paramètre de GridSearchCV\n",
    "hyperparam = dict(C=[0.01,0.1,1,10,100,1000], penalty=['l1', 'l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3ker91g-cjeD",
    "outputId": "5342c87c-4bd2-4f56-ebe3-9ef42c3381c6"
   },
   "outputs": [],
   "source": [
    "reglog_cv = GridSearchCV(estimator = reglog, param_grid = hyperparam, cv=StratifiedKFold(5))\n",
    "reglog_cv.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des hyperparamètres optimaux et de l'accuracy pour chaque jeu d'hyperparamètres\n",
    "print(\"Meilleurs hyperparamètres sur le jeu d'entraînement:\")\n",
    "print(reglog_cv.best_params_)\n",
    "print(\"\\nRésultats de la validation croisée :\")\n",
    "for mean, std, params in zip(\n",
    "        reglog_cv.cv_results_['mean_test_score'], # score moyen\n",
    "        reglog_cv.cv_results_['std_test_score'],  # écart-type du score\n",
    "        reglog_cv.cv_results_['params']           # valeur de l'hyperparamètre\n",
    "    ):\n",
    "\n",
    "    print(\"'accuracy' = {:.5f} (+/-{:.03f}) for {}\".format(mean,std*2,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nDEZDAV3hIh8"
   },
   "source": [
    "## **9. Sauvegarde du modèle avec le module pickle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "396Eb9DkYise"
   },
   "source": [
    "Maintenant qu'on a fait tout le boulot, on pourrait vouloir sauvegarder le modèle pour le réutiliser plus tard pour prédire de nouvelles données par exemple. On peut faire ça avec [pickle](https://docs.python.org/2/library/pickle.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfJ7xJxey-Zy"
   },
   "outputs": [],
   "source": [
    "# sauvegarder le modèle\n",
    "filename = 'logistique_final.sav'\n",
    "pickle.dump(reglog_cv.best_estimator_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "B3YEWFvx07iy",
    "outputId": "edbedb9a-71d3-46f2-8636-bdbafe86fc1b"
   },
   "outputs": [],
   "source": [
    "# recharger le modèle\n",
    "logisitique_sauvegarde = pickle.load(open(filename, 'rb')) \n",
    "print(logisitique_sauvegarde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. Autres modèles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Un kNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue directement l'étape de validation croisée pour déterminer les meilleurs hyperparamètres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule commentée car temps d'exécution un peu long : on obtient k=22\n",
    "# On fixe les valeurs des hyperparamètres à tester\n",
    "# On peut tester 'metric':['euclidean','manhattan'], 'weights':['uniform','distance'] mais c'est long\n",
    "# et on obtient 'euclidean' et 'uniform' comme meilleurs param\n",
    "\"\"\"hyperparam = {'n_neighbors':list(range(2,41,2))}\n",
    "knn_cv = GridSearchCV(KNeighborsClassifier(), param_grid=hyperparam, cv=4, scoring='accuracy')\n",
    "knn_cv.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Meilleurs hyperparamètres sur le jeu d'entraînement:\")\n",
    "print(knn_cv.best_params_)\n",
    "print(\"\\nRésultats de la validation croisée :\")\n",
    "for mean, std, params in zip(knn_cv.cv_results_['mean_test_score'],knn_cv.cv_results_['std_test_score'], knn_cv.cv_results_['params']):\n",
    "    print(\"'accuracy' = {:.5f} (+/-{:.03f}) for {}\".format(mean,std*2,params))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=22)\n",
    "knn.fit(X_train_processed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle\n",
    "evaluation(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Un SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention,c'est un peu long. On pourrait aussi tester d'autres hyperparamètres (kernel, gamma, etc...)\n",
    "hyperparam = {'C': [0.001, 1, 100, 1000]}\n",
    "svm_cv = GridSearchCV(SVC(kernel = 'rbf', random_state=0), param_grid=hyperparam, cv=3, scoring='accuracy')\n",
    "svm_cv.fit(X_train_processed, y_train)\n",
    "\n",
    "# Affichage des hyperparamètres optimaux et de l'accuracy pour chaque jeu d'hyperparamètres\n",
    "print(\"Meilleurs hyperparamètres sur le jeu d'entraînement:\")\n",
    "print(svm_cv.best_params_)\n",
    "print(\"\\nRésultats de la validation croisée :\")\n",
    "for mean, std, params in zip(svm_cv.cv_results_['mean_test_score'], svm_cv.cv_results_['std_test_score'], svm_cv.cv_results_['params']):\n",
    "    print(\"'accuracy' = {:.5f} (+/-{:.03f}) for {}\".format(mean,std*2,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ajouter le paramètre `probability=True` pour avoir un calcul des probabilités et pouvoir tracer la courbe ROC. Pour rappel, ce calcul se fait par validation croisée en utilisant une régression logistique. Plusieurs problèmes :\n",
    "- les probabilités obtenues ne sont pas toujours en accord avec la prédiction du classifieur SVM\n",
    "- cela augmente considérablement le temps d'exécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=1, probability=True)\n",
    "svm.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(svm)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "US Income Final.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
