{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cas pratique sur la base de données diamonds  \n",
    "### Import de la base de données  \n",
    "La base de données diamonds, que vous connaissez déjà pour avoir travaillé dessus notamment avec R, fait partie des bases que databricks met à disposition directement sur son système de gestion de données (DBFS).  Vous la trouverez au format csv en suivant ce chemin : `/databricks-datasets/Rdatasets/data-001/csv/ggplot2`.  \n",
    "- Affichez les bases qui se trouvent dans ce même chemin avec la fonction `dbutils.fs.ls`.  \n",
    "- Importez la base `diamonds` en utilisant `spark.read` et affichez les 10 premières lignes.  \n",
    "- utilisez la fonction `printSchema()` pour affichez les variables de la base et leurs types. Si les types ne correspondent pas, revenez à votre import et spécifiez la valeur du paramètre `inferSchema`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques manipulations de bases de données  \n",
    "L'API dataframes de Spark offre un grand nombre de fonctions natives qui permettent de mettre en oeuvre la pluspart des traitements que l'on a l'habitude de faire avec `pandas`. Vous pouvez notamment trouver un inventaire de ces fonctions dans [cet article](https://hackersandslackers.com/transforming-pyspark-dataframes/). En vous aidant de cette syntaxe, faites le traitement suivant :   \n",
    "- Dans la table `diamonds`, créez une nouvelle variable `categ_price`, égale à :  \n",
    "  - \"low\" si le prix du diamant est inférieur à 1000\\$,  \n",
    "  - \"medium\" si le prix du diamant est inférieur à 3000\\$,  \n",
    "  - \"high\" si le prix du diamant est inférieur à 8000\\$,\n",
    "  - \"very high\" si le prix est au delà.  \n",
    " _Indications_ : Vous aurez besoin pour cette question des fonctions `withColumn()`, `when()`, `col()`, et `lit()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL  \n",
    "Databricks vous offre aussi la possibilité de coder directement en SQL. \n",
    "- Refaites l'import des données (dans une table `diamonds_sql`) et la création de `categ_price` en utilisant le langage SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stockez la table SQL avec categ_price dans un dataframe python que vous nommerez `df_sql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLlib  \n",
    "Un des grands avantages de Spark est sa librairie MLlib, qui permet de faire tourner un grand nombre de modèles de régressions, classifications, etc... Même si cette librairie n'est pas aussi complète que `scitkit-learn`, elle permet tout de même de rendre accessibles beaucoup de modèles pour des bases de données très volumineuses. Vous pouvez explorer les possibilités offertes par cette librairie en parcourant [sa documentation](https://spark.apache.org/docs/latest/ml-guide.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression linéaire   \n",
    "Avec MLlib, la régression linéaire se fait à partir de deux variables :  \n",
    "1) une variable contenant toutes les valeurs numériques de nos variables explicatives concaténées dans un même vecteur grâce à la fonction `VectorAssembler`.    \n",
    "2) la variable que l'on souhaite expliquer (pour nous, ça sera le prix).  \n",
    "Vous pouvez par exemple vous inspirer de [cet article](https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a) dans lequel l'auteure décrit bien les différentes étapes pour mener à bien sa régression.  \n",
    "\n",
    "- Avant de mener votre régression, transformez vos variables caractères en indicatrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Analyse de l'impact des caractéristiques du diamant sur le prix__  \n",
    "- Créez un dataframe contenant une colonne regroupant l'ensemble des variables explicatives passées en numériques et une colonne contenant le prix.  \n",
    "- Faites tourner un modèle de régression linéaire et commentez les coefficients et le R2 de votre modèle. \n",
    "- Évaluez maintenant la qualité prédictive de votre modèle en créant une base d'entraînement et une base de test et en sortant la RMSE et la MAE de votre modèle sur la base de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification  \n",
    "- Entraînez un modèle randomforest qui permettent de classer le diamant en `categ_price` en fonction de ses caractéristiques. Proposez des indicateurs pour évaluer la qualité prédictive de votre modèle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "name": "cas pratique diamonds",
  "notebookId": 929713162422029
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
