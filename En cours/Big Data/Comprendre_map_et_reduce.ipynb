{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comprendre MapReduce**\n",
    "\n",
    "## **Map**\n",
    "\n",
    "```map``` prend en argument une fonction et une collection et retourne une collection. La fonction étant appliquée sur chaque élément de la collection.\n",
    "\n",
    "**Exo1:** Utiliser la fonction ```map``` pour multiplier par 2 les éléments d'une liste. Faire une version en définissant une fonction et une seconde version en utilisant une fonction anonyme ```lambda```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo2:** Créer une liste de 1000 entiers aléatoires. À l'aide de la fonction `map` retourner une collection qui contient `True` si le nombre était pair et `False` sinon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pour faire simple, la seule différence entre le ```map``` de python et celui de spark c'est que le ```map``` de ce dernier découpe le calul sur plusieurs machines pour paralléliser le traitement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reduce**\n",
    "\n",
    "La fonction ```reduce``` prend en entrée une collection et retourne une réduction de celle ci en lui appliquant une fonction d'agrégation itérative, c'est-à-dire, une fonction qui lit les valeurs de la liste de gauche à droite et ne renvoie qu'une seule valeur agrégée.  \n",
    "La fonction d'agrégation doit donc prendre 2 arguments et ne renvoyer qu'une seule valeur.\n",
    "\n",
    "Par exemple, ```reduce``` permet de calculer la somme des éléments d'une liste, ce qu'on va faire (enfin vous allez faire) de suite.\n",
    "\n",
    "**Exo3:** calculer la somme de la liste ```a``` :\n",
    ">1. en utilisant une boucle ```for```\n",
    ">2. en utilisant la fonction ```reduce``` du module ```functools```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo4:** générer une liste de 20 entiers entre 0 et 1000 et calculer le maximum de cette liste à l'aide de la fonction ```reduce```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo5:** importer la fonction ```accumulate``` du module ```itertools```, comprendre comment elle marche, la tester et la comparer avec ```reduce``` sur les 2 exemples précédents (somme et maximum d'une liste). Quelles sont les différences ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comme pour la fonction ```map``` la seule différence entre le ```reduce``` de python et celui de spark c'est que celui de spark découpe en plusieurs morceaux et parallélise le traitement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Petit bonus : Filter**\n",
    "\n",
    "\n",
    "**Exo6**: créer une liste avec les valeurs suivantes : [-1, 3, 2, -1, 6, 8] puis utiliser la fonction ```filter``` pour récupérer uniquement les valeurs positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Map et Reduce**\n",
    "\n",
    "On considère le mega big dataset suivant : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo7:** utiliser la fonction ```map``` pour séparer chaque phrase en en mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo8:** à l'aide de ```map``` et/ou ```reduce``` renvoyer le nombre total de mots dans ```a```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **WordCount : le \"hello world\" du MapReduce**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exo9:** on va illustrer le fonctionnement de MapReduce pour compter le nombre d'occurence de chaque mot dans la variable ```text``` définie ci-dessous. Il faut donc éxecuter les 4 étapes suivantes (le preprocessing étant un petit supplément) :\n",
    ">1. SPLIT: découpage du texte en 4 sous-parties\n",
    ">2. petite étape de peprocessing avec :\n",
    ">>- suppression de la ponctuation,\n",
    ">>- passage en minuscules\n",
    ">>- suppression des mots de 1, 2 ou 3 lettres\n",
    ">3. MAP: avec la fonction ```map``` renvoyer une liste de (clé, valeur) : ici clé=mot et valeur=occurence=1\n",
    ">4. SHUFFLE (& SORT): regroupement des résultats : on doit avoir pour chaque clé le couple (clé, [val, val, val,...]) : ici (mot, [1,1,1,...])\n",
    ">5. REDUCE: sommer les occurences uniques de chaque mot pour obtenir le nombre d'occurrences totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Si vous voulez mon avis concernant la morosité conjoncturelle, \\\n",
    "je n'exclus pas de réorganiser la simultanéité des hypothèses réalisables, \\\n",
    "avec toute la prudence requise. Eu égard à la fragilité actuelle, il ne faut \\\n",
    "pas s'interdire de se remémorer précisément les organisations matricielles \\\n",
    "opportunes, avec beaucoup de recul. Afin de circonvenir à cette inflexion de \\\n",
    "l'époque actuelle, je recommande d'essayer la somme des stratégies envisageables, \\\n",
    "même si ce n'est pas facile. Vu la dualité de la situation conjoncturelle, il ne \\\n",
    "faut pas négliger de gérer certaines synergies optimales, parce que nous le valons \\\n",
    "bien. Nonobstant la dualité de la situation observée, je n'exclus pas d'inventorier \\\n",
    "la somme des modalités réalisables, parce qu'il est temps d'agir. Si vous voulez mon \\\n",
    "avis concernant la baisse de confiance présente, je n'exclus pas d'inventorier la \\\n",
    "globalité des améliorations pertinentes, très attentivement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pour : finir moyenne de liste et temps d'éxecution**\n",
    "\n",
    "**Exo10:** à l'aide des fonctions ```map``` et ```reduce```, on va calculer la moyenne des éléments d'une liste. Et sans utiliser ```len()```...\n",
    ">1. créer une liste d'entiers aléatoires de taille 10^7\n",
    ">2. utiliser ```map``` et ```reduce``` pour caluler la moyenne sur cette liste\n",
    ">3. utiliser ```%%time``` pour mesurer le temps d'éxecution de ce calcul\n",
    ">4. découper la liste en 5 sous-listes de tailles égales\n",
    ">5. importer le module Pool de la libraire multiprocessing et l'utiliser pour paralléliser les calculs sur chaque sous-liste. L'idée est de définir par exemple une fonction MapReduce_average qui reprend votre méthode utilisée pour le calcul de la moyenne et utiliser pool.map(MapReduce_average, liste_splitée)\n",
    ">6. regarder avec %%time les différences de temps d'éxecution des 2 méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Supplément**\n",
    "\n",
    "**Exo11:** Calculer en utilisant le paradigme MapReduce le produit d'une matrice M avec un vecteur V.  \n",
    "Ça peut paraître inutile mais cette opération est derrière l'algorithme du PageRank de Google, c'est d'ailleurs en partie pour ce calcul que MapReduce a été conçu. Dans ce cas, la dimension du problème est le nombre de pages web indexées, soit clairement un problème de Big Data.  \n",
    "Par ailleurs, on l'a vu dans la régression linéaire notamment mais pas, ce produit $matrice*vecteur$ est omniprésent dans les problèmes d'optimisation aussi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
